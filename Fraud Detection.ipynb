{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data is** <font color='red'>**Imbalanced**</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount'] = sc.fit_transform(pd.DataFrame(df['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1       473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit = df[df['Class'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = df[df['Class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    275190.000000\n",
       "mean          0.008682\n",
       "std           1.012309\n",
       "min          -0.353229\n",
       "25%          -0.327682\n",
       "50%          -0.258275\n",
       "75%          -0.033782\n",
       "max         102.362243\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legit.Amount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    473.000000\n",
       "mean       0.142021\n",
       "std        1.040346\n",
       "min       -0.353229\n",
       "25%       -0.349231\n",
       "50%       -0.313968\n",
       "75%        0.070128\n",
       "max        8.146182\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.Amount.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Viz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAGwCAYAAACAZ5AeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqRklEQVR4nO3dfVDU9d7/8deCcuPNQt4AcknepKUm6RUq7rGcTMY1yevySOdSc5K8nQw8R7cUOSlapzOco9PlzfHu6jSFzeRknnO00sK4MPE6ipoYeZMwanbI0UXSYJMUEPb3Rz++46Yl0scW9PmY2Rn3+33vdz9sYzzb/e43m9fr9QoAAAA/S4C/FwAAAHA7IKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMaOHvBdxJ6urqdObMGbVt21Y2m83fywEAAA3g9Xr17bffKjo6WgEBP/5+FFH1Czpz5oxiYmL8vQwAANAIX331lTp37vyj+4mqX1Dbtm0lff8PxW63+3k1AACgITwej2JiYqzf4z+GqPoF1X/kZ7fbiSoAAJqZG526w4nqAAAABhBVAAAABhBVAAAABhBVAAAABhBVAAAABhBVAAAABhBVAAAABhBVAAAABhBVAAAABhBVAAAABhBVAAAABhBVAAAABhBVAAAABhBVAAAABhBVAAAABrTw9wJgXtzcN/29BKDJKVg6yd9LAHCb450qAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA/waVZmZmRo4cKDatm2riIgIjRkzRsXFxT4zjzzyiGw2m8/tmWee8ZkpKSlRYmKiWrVqpYiICM2dO1dXrlzxmdm5c6cefPBBBQcHq0ePHsrKyrpmPatXr1bXrl0VEhKi+Ph47d+/32f/5cuXlZKSovbt26tNmzZKSkpSaWmpmRcDAAA0a36Nqry8PKWkpGjv3r3KyclRTU2NRowYocrKSp+56dOn6+zZs9ZtyZIl1r7a2lolJiaqurpae/bs0fr165WVlaWMjAxr5tSpU0pMTNSwYcNUWFio2bNna9q0adq+fbs1s3HjRrlcLi1atEgHDx5Uv3795HQ6de7cOWtmzpw5ev/997Vp0ybl5eXpzJkzGjt27C18hQAAQHNh83q9Xn8vol5ZWZkiIiKUl5enoUOHSvr+nar+/ftr+fLl133Mhx9+qMcff1xnzpxRZGSkJGndunVKS0tTWVmZgoKClJaWpm3btunIkSPW48aPH6/y8nJlZ2dLkuLj4zVw4ECtWrVKklRXV6eYmBjNmjVL8+fPV0VFhTp27KgNGzboiSeekCQVFRWpd+/eys/P1+DBg2/483k8HoWFhamiokJ2u73Rr9ONxM1985YdG2iuCpZO8vcSADRTDf393aTOqaqoqJAktWvXzmf7W2+9pQ4dOqhv375KT0/Xd999Z+3Lz89XbGysFVSS5HQ65fF4dPToUWsmISHB55hOp1P5+fmSpOrqahUUFPjMBAQEKCEhwZopKChQTU2Nz0yvXr109913WzM/VFVVJY/H43MDAAC3pxb+XkC9uro6zZ49W0OGDFHfvn2t7U8++aS6dOmi6OhoHTp0SGlpaSouLtY//vEPSZLb7fYJKknWfbfb/ZMzHo9Hly5d0jfffKPa2trrzhQVFVnHCAoKUnh4+DUz9c/zQ5mZmXrxxRdv8pUAAADNUZOJqpSUFB05ckT//Oc/fbbPmDHD+nNsbKw6deqk4cOH6+TJk7rnnnt+6WXelPT0dLlcLuu+x+NRTEyMH1cEAABulSbx8V9qaqq2bt2qjz/+WJ07d/7J2fj4eEnSiRMnJElRUVHXfAOv/n5UVNRPztjtdoWGhqpDhw4KDAy87szVx6iurlZ5efmPzvxQcHCw7Ha7zw0AANye/BpVXq9Xqamp2rx5s3bs2KFu3brd8DGFhYWSpE6dOkmSHA6HDh8+7PMtvZycHNntdvXp08eayc3N9TlOTk6OHA6HJCkoKEhxcXE+M3V1dcrNzbVm4uLi1LJlS5+Z4uJilZSUWDMAAODO5deP/1JSUrRhwwa9++67atu2rXVuUlhYmEJDQ3Xy5Elt2LBBo0aNUvv27XXo0CHNmTNHQ4cO1QMPPCBJGjFihPr06aOnnnpKS5Yskdvt1oIFC5SSkqLg4GBJ0jPPPKNVq1Zp3rx5mjJlinbs2KF33nlH27Zts9bicrmUnJysAQMGaNCgQVq+fLkqKys1efJka01Tp06Vy+VSu3btZLfbNWvWLDkcjgZ98w8AANze/BpVa9eulfT9ZROu9sYbb+jpp59WUFCQ/vd//9cKnJiYGCUlJWnBggXWbGBgoLZu3aqZM2fK4XCodevWSk5O1ksvvWTNdOvWTdu2bdOcOXO0YsUKde7cWa+99pqcTqc1M27cOJWVlSkjI0Nut1v9+/dXdna2z8nry5YtU0BAgJKSklRVVSWn06k1a9bcolcHAAA0J03qOlW3O65TBfgP16kC0FjN8jpVAAAAzRVRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYABRBQAAYIBfoyozM1MDBw5U27ZtFRERoTFjxqi4uNhn5vLly0pJSVH79u3Vpk0bJSUlqbS01GempKREiYmJatWqlSIiIjR37lxduXLFZ2bnzp168MEHFRwcrB49eigrK+ua9axevVpdu3ZVSEiI4uPjtX///pteCwAAuDP5Nary8vKUkpKivXv3KicnRzU1NRoxYoQqKyutmTlz5uj999/Xpk2blJeXpzNnzmjs2LHW/traWiUmJqq6ulp79uzR+vXrlZWVpYyMDGvm1KlTSkxM1LBhw1RYWKjZs2dr2rRp2r59uzWzceNGuVwuLVq0SAcPHlS/fv3kdDp17ty5Bq8FAADcuWxer9fr70XUKysrU0REhPLy8jR06FBVVFSoY8eO2rBhg5544glJUlFRkXr37q38/HwNHjxYH374oR5//HGdOXNGkZGRkqR169YpLS1NZWVlCgoKUlpamrZt26YjR45YzzV+/HiVl5crOztbkhQfH6+BAwdq1apVkqS6ujrFxMRo1qxZmj9/foPWciMej0dhYWGqqKiQ3W43+tpdLW7um7fs2EBzVbB0kr+XAKCZaujv7yZ1TlVFRYUkqV27dpKkgoIC1dTUKCEhwZrp1auX7r77buXn50uS8vPzFRsbawWVJDmdTnk8Hh09etSaufoY9TP1x6iurlZBQYHPTEBAgBISEqyZhqzlh6qqquTxeHxuAADg9tRkoqqurk6zZ8/WkCFD1LdvX0mS2+1WUFCQwsPDfWYjIyPldrutmauDqn5//b6fmvF4PLp06ZK+/vpr1dbWXnfm6mPcaC0/lJmZqbCwMOsWExPTwFcDAAA0N00mqlJSUnTkyBG9/fbb/l6KMenp6aqoqLBuX331lb+XBAAAbpEW/l6AJKWmpmrr1q3atWuXOnfubG2PiopSdXW1ysvLfd4hKi0tVVRUlDXzw2/p1X8j7+qZH35Lr7S0VHa7XaGhoQoMDFRgYOB1Z64+xo3W8kPBwcEKDg6+iVcCAAA0V359p8rr9So1NVWbN2/Wjh071K1bN5/9cXFxatmypXJzc61txcXFKikpkcPhkCQ5HA4dPnzY51t6OTk5stvt6tOnjzVz9THqZ+qPERQUpLi4OJ+Zuro65ebmWjMNWQsAALhz+fWdqpSUFG3YsEHvvvuu2rZta52bFBYWptDQUIWFhWnq1KlyuVxq166d7Ha7Zs2aJYfDYX3bbsSIEerTp4+eeuopLVmyRG63WwsWLFBKSor1LtEzzzyjVatWad68eZoyZYp27Nihd955R9u2bbPW4nK5lJycrAEDBmjQoEFavny5KisrNXnyZGtNN1oLAAC4c/k1qtauXStJeuSRR3y2v/HGG3r66aclScuWLVNAQICSkpJUVVUlp9OpNWvWWLOBgYHaunWrZs6cKYfDodatWys5OVkvvfSSNdOtWzdt27ZNc+bM0YoVK9S5c2e99tprcjqd1sy4ceNUVlamjIwMud1u9e/fX9nZ2T4nr99oLQAA4M7VpK5TdbvjOlWA/3CdKgCN1SyvUwUAANBcEVUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGEFUAAAAGNCqqHn30UZWXl1+z3ePx6NFHH/25awIAAGh2GhVVO3fuVHV19TXbL1++rP/7v//72YsCAABoblrczPChQ4esP3/++edyu93W/draWmVnZ+vf/u3fzK0OAACgmbipqOrfv79sNptsNtt1P+YLDQ3VX/7yF2OLAwAAaC5uKqpOnTolr9er7t27a//+/erYsaO1LygoSBEREQoMDDS+SAAAgKbupqKqS5cukqS6urpbshgAAIDmqtGXVDh+/LheffVVvfzyy3rppZd8bg21a9cujR49WtHR0bLZbNqyZYvP/qefftr6uLH+NnLkSJ+ZCxcuaOLEibLb7QoPD9fUqVN18eJFn5lDhw7p4YcfVkhIiGJiYrRkyZJr1rJp0yb16tVLISEhio2N1QcffOCz3+v1KiMjQ506dVJoaKgSEhJ0/PjxBv+sAADg9nZT71TV++tf/6qZM2eqQ4cOioqKks1ms/bZbDZlZGQ06DiVlZXq16+fpkyZorFjx153ZuTIkXrjjTes+8HBwT77J06cqLNnzyonJ0c1NTWaPHmyZsyYoQ0bNkj6/jIPI0aMUEJCgtatW6fDhw9rypQpCg8P14wZMyRJe/bs0YQJE5SZmanHH39cGzZs0JgxY3Tw4EH17dtXkrRkyRKtXLlS69evV7du3bRw4UI5nU59/vnnCgkJafiLBwAAbks2r9frvdkHdenSRc8++6zS0tLMLcRm0+bNmzVmzBhr29NPP63y8vJr3sGqd+zYMfXp00effPKJBgwYIEnKzs7WqFGjdPr0aUVHR2vt2rV64YUX5Ha7FRQUJEmaP3++tmzZoqKiIknSuHHjVFlZqa1bt1rHHjx4sPr3769169bJ6/UqOjpazz33nJ5//nlJUkVFhSIjI5WVlaXx48c36Gf0eDwKCwtTRUWF7Hb7zb5EDRY3981bdmyguSpYOsnfSwDQTDX093ejPv775ptv9Jvf/KbRi7sZO3fuVEREhO677z7NnDlT58+ft/bl5+crPDzcCipJSkhIUEBAgPbt22fNDB061AoqSXI6nSouLtY333xjzSQkJPg8r9PpVH5+vqTvT9B3u90+M2FhYYqPj7dmrqeqqkoej8fnBgAAbk+Niqrf/OY3+uijj0yv5RojR47Um2++qdzcXP35z39WXl6eHnvsMdXW1kqS3G63IiIifB7TokULtWvXzrqGltvtVmRkpM9M/f0bzVy9/+rHXW/mejIzMxUWFmbdYmJiburnBwAAzUejzqnq0aOHFi5cqL179yo2NlYtW7b02f/b3/7WyOKu/lgtNjZWDzzwgO655x7t3LlTw4cPN/Ict1J6erpcLpd13+PxEFYAANymGhVVr776qtq0aaO8vDzl5eX57LPZbMai6oe6d++uDh066MSJExo+fLiioqJ07tw5n5krV67owoULioqKkiRFRUWptLTUZ6b+/o1mrt5fv61Tp04+M/379//R9QYHB19zYj0AALg9Nerjv1OnTv3o7YsvvjC9Rsvp06d1/vx5K2wcDofKy8tVUFBgzezYsUN1dXWKj4+3Znbt2qWamhprJicnR/fdd5/uuusuayY3N9fnuXJycuRwOCRJ3bp1U1RUlM+Mx+PRvn37rBkAAHBna/R1qky4ePGiCgsLVVhYKOn7WCssLFRJSYkuXryouXPnau/evfryyy+Vm5ur//zP/1SPHj3kdDolSb1799bIkSM1ffp07d+/X7t371ZqaqrGjx+v6OhoSdKTTz6poKAgTZ06VUePHtXGjRu1YsUKn4/lfve73yk7O1uvvPKKioqKtHjxYh04cECpqamSvn/3bfbs2Xr55Zf13nvv6fDhw5o0aZKio6N9vq0IAADuXI36+G/KlCk/uf/1119v0HEOHDigYcOGWffrQyc5OVlr167VoUOHtH79epWXlys6OlojRozQH/7wB5+P1N566y2lpqZq+PDhCggIUFJSklauXGntDwsL00cffaSUlBTFxcWpQ4cOysjIsK5RJUm/+tWvtGHDBi1YsEC///3v1bNnT23ZssW6RpUkzZs3T5WVlZoxY4bKy8v10EMPKTs7m2tUAQAASY28TtWvf/1rn/s1NTU6cuSIysvL9eijj+of//iHsQXeTrhOFeA/XKcKQGM19Pd3o96p2rx58zXb6urqNHPmTN1zzz2NOSQAAECzZuycqoCAALlcLi1btszUIQEAAJoNoyeqnzx5UleuXDF5SAAAgGahUR//Xf3NOUnyer06e/astm3bpuTkZCMLAwAAaE4aFVWffvqpz/2AgAB17NhRr7zyyg2/GQgAAHA7alRUffzxx6bXAQAA0Kw1KqrqlZWVqbi4WJJ03333qWPHjkYWBQAA0Nw06kT1yspKTZkyRZ06ddLQoUM1dOhQRUdHa+rUqfruu+9MrxEAAKDJa1RUuVwu5eXl6f3331d5ebnKy8v17rvvKi8vT88995zpNQIAADR5jfr47+9//7v+9re/6ZFHHrG2jRo1SqGhofqv//ovrV271tT6AAAAmoVGvVP13XffKTIy8prtERERfPwHAADuSI2KKofDoUWLFuny5cvWtkuXLunFF1+Uw+EwtjgAAIDmolEf/y1fvlwjR45U586d1a9fP0nSZ599puDgYH300UdGFwgAANAcNCqqYmNjdfz4cb311lsqKiqSJE2YMEETJ05UaGio0QUCAAA0B42KqszMTEVGRmr69Ok+219//XWVlZUpLS3NyOIAAACai0adU/U///M/6tWr1zXb77//fq1bt+5nLwoAAKC5aVRUud1uderU6ZrtHTt21NmzZ3/2ogAAAJqbRkVVTEyMdu/efc323bt3Kzo6+mcvCgAAoLlp1DlV06dP1+zZs1VTU6NHH31UkpSbm6t58+ZxRXUAAHBHalRUzZ07V+fPn9ezzz6r6upqSVJISIjS0tKUnp5udIEAAADNQaOiymaz6c9//rMWLlyoY8eOKTQ0VD179lRwcLDp9QEAADQLjYqqem3atNHAgQNNrQUAAKDZatSJ6gAAAPBFVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABjg16jatWuXRo8erejoaNlsNm3ZssVnv9frVUZGhjp16qTQ0FAlJCTo+PHjPjMXLlzQxIkTZbfbFR4erqlTp+rixYs+M4cOHdLDDz+skJAQxcTEaMmSJdesZdOmTerVq5dCQkIUGxurDz744KbXAgAA7lx+jarKykr169dPq1evvu7+JUuWaOXKlVq3bp327dun1q1by+l06vLly9bMxIkTdfToUeXk5Gjr1q3atWuXZsyYYe33eDwaMWKEunTpooKCAi1dulSLFy/Wq6++as3s2bNHEyZM0NSpU/Xpp59qzJgxGjNmjI4cOXJTawEAAHcum9fr9fp7EZJks9m0efNmjRkzRtL37wxFR0frueee0/PPPy9JqqioUGRkpLKysjR+/HgdO3ZMffr00SeffKIBAwZIkrKzszVq1CidPn1a0dHRWrt2rV544QW53W4FBQVJkubPn68tW7aoqKhIkjRu3DhVVlZq69at1noGDx6s/v37a926dQ1aS0N4PB6FhYWpoqJCdrvdyOt2PXFz37xlxwaaq4Klk/y9BADNVEN/fzfZc6pOnTolt9uthIQEa1tYWJji4+OVn58vScrPz1d4eLgVVJKUkJCggIAA7du3z5oZOnSoFVSS5HQ6VVxcrG+++caaufp56mfqn6cha7meqqoqeTwenxsAALg9NdmocrvdkqTIyEif7ZGRkdY+t9utiIgIn/0tWrRQu3btfGaud4yrn+PHZq7ef6O1XE9mZqbCwsKsW0xMzA1+agAA0Fw12ai6HaSnp6uiosK6ffXVV/5eEgAAuEWabFRFRUVJkkpLS322l5aWWvuioqJ07tw5n/1XrlzRhQsXfGaud4yrn+PHZq7ef6O1XE9wcLDsdrvPDQAA3J6abFR169ZNUVFRys3NtbZ5PB7t27dPDodDkuRwOFReXq6CggJrZseOHaqrq1N8fLw1s2vXLtXU1FgzOTk5uu+++3TXXXdZM1c/T/1M/fM0ZC0AAODO5teounjxogoLC1VYWCjp+xPCCwsLVVJSIpvNptmzZ+vll1/We++9p8OHD2vSpEmKjo62viHYu3dvjRw5UtOnT9f+/fu1e/dupaamavz48YqOjpYkPfnkkwoKCtLUqVN19OhRbdy4UStWrJDL5bLW8bvf/U7Z2dl65ZVXVFRUpMWLF+vAgQNKTU2VpAatBQAA3Nla+PPJDxw4oGHDhln360MnOTlZWVlZmjdvniorKzVjxgyVl5froYceUnZ2tkJCQqzHvPXWW0pNTdXw4cMVEBCgpKQkrVy50tofFhamjz76SCkpKYqLi1OHDh2UkZHhcy2rX/3qV9qwYYMWLFig3//+9+rZs6e2bNmivn37WjMNWQsAALhzNZnrVN0JuE4V4D9cpwpAYzX761QBAAA0J0QVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAUQVAACAAU06qhYvXiybzeZz69Wrl7X/8uXLSklJUfv27dWmTRslJSWptLTU5xglJSVKTExUq1atFBERoblz5+rKlSs+Mzt37tSDDz6o4OBg9ejRQ1lZWdesZfXq1eratatCQkIUHx+v/fv335KfGQAANE9NOqok6f7779fZs2et2z//+U9r35w5c/T+++9r06ZNysvL05kzZzR27Fhrf21trRITE1VdXa09e/Zo/fr1ysrKUkZGhjVz6tQpJSYmatiwYSosLNTs2bM1bdo0bd++3ZrZuHGjXC6XFi1apIMHD6pfv35yOp06d+7cL/MiAACAJs/m9Xq9/l7Ej1m8eLG2bNmiwsLCa/ZVVFSoY8eO2rBhg5544glJUlFRkXr37q38/HwNHjxYH374oR5//HGdOXNGkZGRkqR169YpLS1NZWVlCgoKUlpamrZt26YjR45Yxx4/frzKy8uVnZ0tSYqPj9fAgQO1atUqSVJdXZ1iYmI0a9YszZ8/v8E/j8fjUVhYmCoqKmS32xv7stxQ3Nw3b9mxgeaqYOkkfy8BQDPV0N/fTf6dquPHjys6Olrdu3fXxIkTVVJSIkkqKChQTU2NEhISrNlevXrp7rvvVn5+viQpPz9fsbGxVlBJktPplMfj0dGjR62Zq49RP1N/jOrqahUUFPjMBAQEKCEhwZr5MVVVVfJ4PD43AABwe2rSURUfH6+srCxlZ2dr7dq1OnXqlB5++GF9++23crvdCgoKUnh4uM9jIiMj5Xa7JUlut9snqOr31+/7qRmPx6NLly7p66+/Vm1t7XVn6o/xYzIzMxUWFmbdYmJibvo1AAAAzUMLfy/gpzz22GPWnx944AHFx8erS5cueueddxQaGurHlTVMenq6XC6Xdd/j8RBWAADcppr0O1U/FB4ernvvvVcnTpxQVFSUqqurVV5e7jNTWlqqqKgoSVJUVNQ13wasv3+jGbvdrtDQUHXo0EGBgYHXnak/xo8JDg6W3W73uQEAgNtTs4qqixcv6uTJk+rUqZPi4uLUsmVL5ebmWvuLi4tVUlIih8MhSXI4HDp8+LDPt/RycnJkt9vVp08fa+bqY9TP1B8jKChIcXFxPjN1dXXKzc21ZgAAAJp0VD3//PPKy8vTl19+qT179ujXv/61AgMDNWHCBIWFhWnq1KlyuVz6+OOPVVBQoMmTJ8vhcGjw4MGSpBEjRqhPnz566qmn9Nlnn2n79u1asGCBUlJSFBwcLEl65pln9MUXX2jevHkqKirSmjVr9M4772jOnDnWOlwul/76179q/fr1OnbsmGbOnKnKykpNnjzZL68LAABoepr0OVWnT5/WhAkTdP78eXXs2FEPPfSQ9u7dq44dO0qSli1bpoCAACUlJamqqkpOp1Nr1qyxHh8YGKitW7dq5syZcjgcat26tZKTk/XSSy9ZM926ddO2bds0Z84crVixQp07d9Zrr70mp9NpzYwbN05lZWXKyMiQ2+1W//79lZ2dfc3J6wAA4M7VpK9TdbvhOlWA/3CdKgCNddtcpwoAAKA5IKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKoAAAAMIKpu0urVq9W1a1eFhIQoPj5e+/fv9/eSAABAE0BU3YSNGzfK5XJp0aJFOnjwoPr16yen06lz5875e2kAAMDPiKqb8N///d+aPn26Jk+erD59+mjdunVq1aqVXn/9dX8vDQAA+FkLfy+guaiurlZBQYHS09OtbQEBAUpISFB+fv51H1NVVaWqqirrfkVFhSTJ4/Hc0rXWVl26pccHmqNb/fful/LVnwb7ewlAkxMzf+8tPX79vz+8Xu9PzhFVDfT111+rtrZWkZGRPtsjIyNVVFR03cdkZmbqxRdfvGZ7TEzMLVkjgB8X9pdn/L0EALdKZtgv8jTffvutwsJ+/LmIqlsoPT1dLpfLul9XV6cLFy6offv2stlsflwZfgkej0cxMTH66quvZLfb/b0cAAbx9/vO4vV69e233yo6Ovon54iqBurQoYMCAwNVWlrqs720tFRRUVHXfUxwcLCCg4N9toWHh9+qJaKJstvt/EsXuE3x9/vO8VPvUNXjRPUGCgoKUlxcnHJzc61tdXV1ys3NlcPh8OPKAABAU8A7VTfB5XIpOTlZAwYM0KBBg7R8+XJVVlZq8uTJ/l4aAADwM6LqJowbN05lZWXKyMiQ2+1W//79lZ2dfc3J64D0/ce/ixYtuuYjYADNH3+/cT02742+HwgAAIAb4pwqAAAAA4gqAAAAA4gqAAAAA4gqAAAAA4gq4BZYvXq1unbtqpCQEMXHx2v//v3+XhIAA3bt2qXRo0crOjpaNptNW7Zs8feS0IQQVYBhGzdulMvl0qJFi3Tw4EH169dPTqdT586d8/fSAPxMlZWV6tevn1avXu3vpaAJ4pIKgGHx8fEaOHCgVq1aJen7K+/HxMRo1qxZmj9/vp9XB8AUm82mzZs3a8yYMf5eCpoI3qkCDKqurlZBQYESEhKsbQEBAUpISFB+fr4fVwYAuNWIKsCgr7/+WrW1tddcZT8yMlJut9tPqwIA/BKIKgAAAAOIKsCgDh06KDAwUKWlpT7bS0tLFRUV5adVAQB+CUQVYFBQUJDi4uKUm5trbaurq1Nubq4cDocfVwYAuNVa+HsBwO3G5XIpOTlZAwYM0KBBg7R8+XJVVlZq8uTJ/l4agJ/p4sWLOnHihHX/1KlTKiwsVLt27XT33Xf7cWVoCrikAnALrFq1SkuXLpXb7Vb//v21cuVKxcfH+3tZAH6mnTt3atiwYddsT05OVlZW1i+/IDQpRBUAAIABnFMFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAABgAFEFAA1ks9m0ZcsWfy8DQBNFVAHA/+d2uzVr1ix1795dwcHBiomJ0ejRo33+B9kA8GP4HyoDgKQvv/xSQ4YMUXh4uJYuXarY2FjV1NRo+/btSklJUVFRkb+XCKCJ450qAJD07LPPymazaf/+/UpKStK9996r+++/Xy6XS3v37r3uY9LS0nTvvfeqVatW6t69uxYuXKiamhpr/2effaZhw4apbdu2stvtiouL04EDByRJ//rXvzR69Gjdddddat26te6//3598MEHv8jPCuDW4J0qAHe8CxcuKDs7W3/84x/VunXra/aHh4df93Ft27ZVVlaWoqOjdfjwYU2fPl1t27bVvHnzJEkTJ07Uv//7v2vt2rUKDAxUYWGhWrZsKUlKSUlRdXW1du3apdatW+vzzz9XmzZtbtnPCODWI6oA3PFOnDghr9erXr163dTjFixYYP25a9euev755/X2229bUVVSUqK5c+dax+3Zs6c1X1JSoqSkJMXGxkqSunfv/nN/DAB+xsd/AO54Xq+3UY/buHGjhgwZoqioKLVp00YLFixQSUmJtd/lcmnatGlKSEjQn/70J508edLa99vf/lYvv/yyhgwZokWLFunQoUM/++cA4F9EFYA7Xs+ePWWz2W7qZPT8/HxNnDhRo0aN0tatW/Xpp5/qhRdeUHV1tTWzePFiHT16VImJidqxY4f69OmjzZs3S5KmTZumL774Qk899ZQOHz6sAQMG6C9/+Yvxnw3AL8fmbex/ogHAbeSxxx7T4cOHVVxcfM15VeXl5QoPD5fNZtPmzZs1ZswYvfLKK1qzZo3Pu0/Tpk3T3/72N5WXl1/3OSZMmKDKykq999571+xLT0/Xtm3beMcKaMZ4pwoAJK1evVq1tbUaNGiQ/v73v+v48eM6duyYVq5cKYfDcc18z549VVJSorffflsnT57UypUrrXehJOnSpUtKTU3Vzp079a9//Uu7d+/WJ598ot69e0uSZs+ere3bt+vUqVM6ePCgPv74Y2sfgOaJE9UBQN+fKH7w4EH98Y9/1HPPPaezZ8+qY8eOiouL09q1a6+Z/4//+A/NmTNHqampqqqqUmJiohYuXKjFixdLkgIDA3X+/HlNmjRJpaWl6tChg8aOHasXX3xRklRbW6uUlBSdPn1adrtdI0eO1LJly37JHxmAYXz8BwAAYAAf/wEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABhAVAEAABjw/wB/YSXpZ6fW4wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x= 'Class', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Highly** <font color='red'>**Imbalanced**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Class', axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Baseline Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      LogisticRegression        \n",
      "accuracy_score = 0.9992200678359603\n",
      "f1_score = 0.718954248366013\n",
      "precision_score = 0.8870967741935484\n",
      "recall_score = 0.6043956043956044\n",
      "\n",
      "      DecisionTreeClassifier        \n",
      "accuracy_score = 0.9988935846045018\n",
      "f1_score = 0.680628272251309\n",
      "precision_score = 0.65\n",
      "recall_score = 0.7142857142857143\n",
      "\n",
      "      RandomForestClassifier        \n",
      "accuracy_score = 0.9990568262202311\n",
      "f1_score = 0.6666666666666666\n",
      "precision_score = 0.8\n",
      "recall_score = 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "classifier = {\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    \"DecisionTreeClassifier\" : DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\" : RandomForestClassifier(n_estimators=4, max_depth=3)\n",
    "}\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n      {name}        \")\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(f\"accuracy_score = {accuracy_score(y_test,y_pred)}\")\n",
    "    print(f\"f1_score = {f1_score(y_test,y_pred)}\")\n",
    "    print(f\"precision_score = {precision_score(y_test,y_pred)}\")\n",
    "    print(f\"recall_score = {recall_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **UnderSampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1       473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_sample = legit.sample(n=473)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Dataset\n",
    "new_df = pd.concat([legit_sample,fraud], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    473\n",
       "1    473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = new_df.drop('Class', axis=1)\n",
    "y = new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      LogisticRegression        \n",
      "accuracy_score = 0.9263157894736842\n",
      "f1_score = 0.9300000000000002\n",
      "precision_score = 0.9489795918367347\n",
      "recall_score = 0.9117647058823529\n",
      "\n",
      "      DecisionTreeClassifier        \n",
      "accuracy_score = 0.9157894736842105\n",
      "f1_score = 0.92\n",
      "precision_score = 0.9387755102040817\n",
      "recall_score = 0.9019607843137255\n",
      "\n",
      "      RandomForestClassifier        \n",
      "accuracy_score = 0.9368421052631579\n",
      "f1_score = 0.9387755102040817\n",
      "precision_score = 0.9787234042553191\n",
      "recall_score = 0.9019607843137255\n"
     ]
    }
   ],
   "source": [
    "classifier = {\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    \"DecisionTreeClassifier\" : DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\" : RandomForestClassifier(n_estimators=4, max_depth=3)\n",
    "}\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n      {name}        \")\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(f\"accuracy_score = {accuracy_score(y_test,y_pred)}\")\n",
    "    print(f\"f1_score = {f1_score(y_test,y_pred)}\")\n",
    "    print(f\"precision_score = {precision_score(y_test,y_pred)}\")\n",
    "    print(f\"recall_score = {recall_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **OverSampling : SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Class', axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_os, y_os = SMOTE().fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1    275190\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_os.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_os, y_os, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      LogisticRegression        \n",
      "accuracy_score = 0.9441476797848759\n",
      "f1_score = 0.9423513305702981\n",
      "precision_score = 0.973006990298782\n",
      "recall_score = 0.9135683508172282\n",
      "\n",
      "      DecisionTreeClassifier        \n",
      "accuracy_score = 0.998128565718231\n",
      "f1_score = 0.9981289396719286\n",
      "precision_score = 0.9972955803611943\n",
      "recall_score = 0.9989636928894787\n",
      "\n",
      "      RandomForestClassifier        \n",
      "accuracy_score = 0.9235437334205459\n",
      "f1_score = 0.9177835957953968\n",
      "precision_score = 0.9918287198327738\n",
      "recall_score = 0.8540261440285075\n"
     ]
    }
   ],
   "source": [
    "classifier = {\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    \"DecisionTreeClassifier\" : DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\" : RandomForestClassifier(n_estimators=4, max_depth=3)\n",
    "}\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n      {name}        \")\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(f\"accuracy_score = {accuracy_score(y_test,y_pred)}\")\n",
    "    print(f\"f1_score = {f1_score(y_test,y_pred)}\")\n",
    "    print(f\"precision_score = {precision_score(y_test,y_pred)}\")\n",
    "    print(f\"recall_score = {recall_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By Above Insights We can Conclude that** <font color='green'>**Decision Tree**</font> **ðŸŒ³is best fit model**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Saving Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_os,y_os)                       # Training over Complete Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Saved Models/Credit_Card_Fraud.pkl\"\n",
    "file = open(filename, 'wb')\n",
    "\n",
    "pickle.dump(dt, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Working of Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Random Testing Data from Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.50035806,  0.71036409,  1.61792059, -0.74123644,  0.42690292,\n",
       "        -0.35078037,  1.14785808, -0.96814314,  0.5571131 ,  1.37273383,\n",
       "         1.31832085, -0.35261114, -0.88501641, -0.50280468,  0.81504207,\n",
       "        -0.18911148, -0.83532158,  0.31690832,  1.29251189,  0.37403193,\n",
       "        -0.12957371,  0.14394042, -0.19038989,  0.05164287, -0.82230824,\n",
       "         0.79836485, -1.03495615, -0.68355194, -0.33787674]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n= df.drop('Class', axis=1)\n",
    "f= n.sample()\n",
    "f = f.to_numpy(dtype='float')\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"Saved Models/Credit_Card_Fraud.pkl\", \"rb\")\n",
    "\n",
    "model = pickle.load(file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Transaction\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(f)\n",
    "pred[0]\n",
    "if pred[0] == 0:\n",
    "    print(\"Normal Transaction\")\n",
    "else:\n",
    "    print(\"Fraudulent Transaction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
